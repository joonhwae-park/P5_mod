Using GPU: 0
Testing with arguments: {'distributed': False, 'multiGPU': False, 'fp16': True, 'train': 'ml1m', 'valid': 'ml1m', 'test': 'ml1m', 'batch_size': 16, 'optim': 'adamw', 'warmup_ratio': 0.05, 'lr': 0.001, 'num_workers': 0, 'clip_grad_norm': 1.0, 'losses': 'rating', 'backbone': 't5-small', 'output': '/scratch/jpa2742/P5/snap', 'epoch': 10, 'local_rank': 0, 'comment': '', 'dropout': 0.1, 'tokenizer': 'p5', 'max_text_length': 512, 'do_lower_case': False, 'gen_max_length': 64, 'seed': 42, 'whole_word_embed': True, 'world_size': 1, 'gpu': 0, 'rank': 0}
Using P5Tokenizer with backbone: t5-small
Building Model based on: t5-small
Resized model token embeddings to: 32100
Model and Tokenizer created.
Model loaded from: /scratch/jpa2742/P5/snap/Epoch10.pth
<All keys matched successfully>
Model loading step complete.

Evaluating with rating prompt: 1-1
Data sources root: /scratch/jpa2742/P5/data/ml1m
Computing datum_info for P5_ML1M_Dataset...
Total number of samples for mode 'test': 80278
DataLoader for rating prediction (prompt 1-1) created. Batches: 5018
Starting Rating Prediction Evaluation for prompt 1-1 (RMSE, MAE)...

--- Rating Prediction Results for Prompt 1-1 (on 80278 valid samples) ---
RMSE: 1.6297
MAE:  1.1479
Rating prediction evaluation for prompt 1-1 finished.

Evaluating with rating prompt: 1-2
Data sources root: /scratch/jpa2742/P5/data/ml1m
Computing datum_info for P5_ML1M_Dataset...
Total number of samples for mode 'test': 80278
DataLoader for rating prediction (prompt 1-2) created. Batches: 5018
Starting Rating Prediction Evaluation for prompt 1-2 (RMSE, MAE)...

--- Rating Prediction Results for Prompt 1-2 (on 80278 valid samples) ---
RMSE: 1.6821
MAE:  1.2018
Rating prediction evaluation for prompt 1-2 finished.

Evaluating with rating prompt: 1-5
Data sources root: /scratch/jpa2742/P5/data/ml1m
Computing datum_info for P5_ML1M_Dataset...
Total number of samples for mode 'test': 80278
DataLoader for rating prediction (prompt 1-5) created. Batches: 5018
Starting Rating Prediction Evaluation for prompt 1-5 (RMSE, MAE)...

--- Rating Prediction Results for Prompt 1-5 (on 80278 valid samples) ---
RMSE: 1.6398
MAE:  1.1605
Rating prediction evaluation for prompt 1-5 finished.

Evaluating with rating prompt: 1-6
Data sources root: /scratch/jpa2742/P5/data/ml1m
Computing datum_info for P5_ML1M_Dataset...
Total number of samples for mode 'test': 80278
DataLoader for rating prediction (prompt 1-6) created. Batches: 5018
Starting Rating Prediction Evaluation for prompt 1-6 (RMSE, MAE)...

--- Rating Prediction Results for Prompt 1-6 (on 80278 valid samples) ---
RMSE: 1.6811
MAE:  1.2051
Rating prediction evaluation for prompt 1-6 finished.

Evaluating with rating prompt: 1-7
Data sources root: /scratch/jpa2742/P5/data/ml1m
Computing datum_info for P5_ML1M_Dataset...
Total number of samples for mode 'test': 80278
DataLoader for rating prediction (prompt 1-7) created. Batches: 5018
Starting Rating Prediction Evaluation for prompt 1-7 (RMSE, MAE)...

--- Rating Prediction Results for Prompt 1-7 (on 80278 valid samples) ---
RMSE: 1.7283
MAE:  1.2526
Rating prediction evaluation for prompt 1-7 finished.

Evaluating with rating prompt: 1-10
Data sources root: /scratch/jpa2742/P5/data/ml1m
Computing datum_info for P5_ML1M_Dataset...
Total number of samples for mode 'test': 80278
DataLoader for rating prediction (prompt 1-10) created. Batches: 5018
Starting Rating Prediction Evaluation for prompt 1-10 (RMSE, MAE)...

--- Rating Prediction Results for Prompt 1-10 (on 80278 valid samples) ---
RMSE: 1.6297
MAE:  1.1479
Rating prediction evaluation for prompt 1-10 finished.

Saved detailed predictions to: ./rating_predictions_details.csv

Placeholder for other task evaluations (Sequential, Explanation, etc.)...

--- Evaluation Script Finished ---
