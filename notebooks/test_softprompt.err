
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/scratch/jpa2742/P5/notebooks/test_softprompt_inprompt.py", line 22, in <module>
    from peft import get_peft_model, PromptTuningConfig, PromptEncoderConfig, TaskType
  File "/users/jpa2742/.conda/envs/detic/lib/python3.9/site-packages/peft/__init__.py", line 22, in <module>
    from .auto import (
  File "/users/jpa2742/.conda/envs/detic/lib/python3.9/site-packages/peft/auto.py", line 31, in <module>
    from .mapping import MODEL_TYPE_TO_PEFT_MODEL_MAPPING
  File "/users/jpa2742/.conda/envs/detic/lib/python3.9/site-packages/peft/mapping.py", line 23, in <module>
    from .peft_model import (
  File "/users/jpa2742/.conda/envs/detic/lib/python3.9/site-packages/peft/peft_model.py", line 39, in <module>
    from .tuners import (
  File "/users/jpa2742/.conda/envs/detic/lib/python3.9/site-packages/peft/tuners/__init__.py", line 22, in <module>
    from .loha import LoHaConfig, LoHaModel
  File "/users/jpa2742/.conda/envs/detic/lib/python3.9/site-packages/peft/tuners/loha/__init__.py", line 17, in <module>
    from .layer import Conv2d, Linear, LoHaLayer
  File "/users/jpa2742/.conda/envs/detic/lib/python3.9/site-packages/peft/tuners/loha/layer.py", line 268, in <module>
    class HadaWeight(torch.autograd.Function):
  File "/users/jpa2742/.conda/envs/detic/lib/python3.9/site-packages/peft/tuners/loha/layer.py", line 270, in HadaWeight
    def forward(ctx, w1a, w1b, w2a, w2b, scale=torch.tensor(1)):
/users/jpa2742/.conda/envs/detic/lib/python3.9/site-packages/peft/tuners/loha/layer.py:270: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  def forward(ctx, w1a, w1b, w2a, w2b, scale=torch.tensor(1)):
/users/jpa2742/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'T5Tokenizer'. 
The class this function is called from is 'P5Tokenizer'.
You are using the default legacy behaviour of the <class 'src.tokenization.P5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
